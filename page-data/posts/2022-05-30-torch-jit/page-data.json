{"componentChunkName":"component---src-templates-post-js","path":"/posts/2022-05-30-torch-jit/","result":{"data":{"site":{"siteMetadata":{"title":"MJUN Tech Note","author":"Junya Morioka"}},"markdownRemark":{"id":"b32445d1-147f-517f-b0b1-c0660f12fc59","html":"<p>こんにちは．今回は，PyTorchでサポートされているTorchScriptへの変換を\n行うJITコンパイル機能が，GPUのメモリの節約になる例を紹介したいと思います．</p>\n<h2 id=\"jitコンパイルとは\">JITコンパイルとは</h2>\n<p>JITはJust In Timeの略です．</p>\n<p>JITコンパイルでは，コンパイルと名がついているように，\n機械語への変換を行います．<br>\n通常のコンパイルでは，プログラムを実行する前，\nつまり\"事前コンパイル\"を行いますが，\nJITコンパイルはプログラム\"実行時\"にコンパイルを行います．</p>\n<p>PyTorchではTorchScriotという中間表現に\n変換されるので，Pythonで学習させたモデルをTorchScriptに変換することで\nC++から呼び出したりデプロイ先からPythonに依存せずに呼び出すことが\n可能となります．</p>\n<p>Tensorflowのデプロイ機能に対抗したPyTorch独自のデプロイ機能と言えます．</p>\n<p>チュートリアルは以下にあります．</p>\n<p><a href=\"https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html\">https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html</a></p>\n<p>ドキュメントも参考にして下さい．</p>\n<p><a href=\"https://pytorch.org/docs/stable/jit.html\">https://pytorch.org/docs/stable/jit.html</a></p>\n<h2 id=\"メモリの節約例\">メモリの節約例</h2>\n<p>本来は組み込み等に使いますが，TorchScriptに変換することで\n計算の中間結果をGPUメモリに展開することがなくなり，\nメモリの節約に繋がります．</p>\n<p>物体検出で見られるIoUの計算でメモリの節約例を見ていきます．</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> torch\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">intersection</span><span class=\"token punctuation\">(</span>boxes1<span class=\"token punctuation\">,</span> boxes2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"intersection: 領域の共通部分の面積\n       boxes1に対してすべてのboxes2のペアをつくる\n\n    Args:\n        boxes1 ([type]): N boxes\n        boxes2 ([type]): M boxes\n\n    Returns:\n        tensor: shape [N, M]\n    \"\"\"</span>\n    x_min1<span class=\"token punctuation\">,</span> y_min1<span class=\"token punctuation\">,</span> x_max1<span class=\"token punctuation\">,</span> y_max1 <span class=\"token operator\">=</span> boxes1<span class=\"token punctuation\">.</span>chunk<span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    x_min2<span class=\"token punctuation\">,</span> y_min2<span class=\"token punctuation\">,</span> x_max2<span class=\"token punctuation\">,</span> y_max2 <span class=\"token operator\">=</span> boxes2<span class=\"token punctuation\">.</span>chunk<span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># 重なり部分の高さ</span>\n    all_pairs_min_ymax <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span>y_max1<span class=\"token punctuation\">,</span> y_max2<span class=\"token punctuation\">.</span>t<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    all_pairs_max_ymin <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>y_min1<span class=\"token punctuation\">,</span> y_min2<span class=\"token punctuation\">.</span>t<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    intersect_heights <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>clamp<span class=\"token punctuation\">(</span>all_pairs_min_ymax <span class=\"token operator\">-</span> all_pairs_max_ymin<span class=\"token punctuation\">,</span> <span class=\"token builtin\">min</span><span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># 重なり部分の幅</span>\n    all_pairs_min_xmax <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span>x_max1<span class=\"token punctuation\">,</span> x_max2<span class=\"token punctuation\">.</span>t<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    all_pairs_max_xmin <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>x_min1<span class=\"token punctuation\">,</span> x_min2<span class=\"token punctuation\">.</span>t<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    intersect_widths <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>clamp<span class=\"token punctuation\">(</span>all_pairs_min_xmax <span class=\"token operator\">-</span> all_pairs_max_xmin<span class=\"token punctuation\">,</span> <span class=\"token builtin\">min</span><span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> intersect_heights <span class=\"token operator\">*</span> intersect_widths</code></pre></div>\n<p>このコードは2つのBoxの共通面積を計算する関数です．<br>\n引数として，N個のBoxとM個のBoxを取り，全ての組み合わせについて\n共通領域の面積を求めます．つまり，M x NのTensorが生成されることになります．</p>\n<p>このコードをこのまま実行すると，MとNの数が巨大な時に，\n<code class=\"language-text\">all_pairs_min_ymax, all_pairs_max_ymin, intersect_heights</code>といった計算の中間結果で\nGPUメモリを大幅に消費してしまうことになります．<br>\n例えば，N=242991, M=500(物体検出的に言うと，anchorが242991個，GT Boxが500個の想定)のとき，\nGPUメモリは約460MBも消費されてしまいます．</p>\n<p>ここで役立つのがjitです．中間結果を出力しないためGPUメモリを節約できます．</p>\n<p>デコレータが用意されているので，<code class=\"language-text\">@torch.jit.script</code>を関数の先頭に書くだけで\nJITコンパイルが行われます．</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token decorator annotation punctuation\">@torch<span class=\"token punctuation\">.</span>jit<span class=\"token punctuation\">.</span>script</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">intersection</span><span class=\"token punctuation\">(</span>boxes1<span class=\"token punctuation\">,</span> boxes2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">pass</span></code></pre></div>\n<p>これで中間結果にGPUメモリを取られることがなくなり，\n忌々しいCUDA out of memoryを回避できます．</p>\n<p>また，以下の通りJITコンパイルに対応していない操作もあるので注意して下さい．</p>\n<p><a href=\"https://pytorch.org/docs/stable/jit_unsupported.html#jit-unsupported\">https://pytorch.org/docs/stable/jit_unsupported.html#jit-unsupported</a></p>\n<h2 id=\"参考\">参考</h2>\n<p><a href=\"https://github.com/facebookresearch/maskrcnn-benchmark/issues/18\">https://github.com/facebookresearch/maskrcnn-benchmark/issues/18</a></p>","tableOfContents":"<ul>\n<li><a href=\"#jit%E3%82%B3%E3%83%B3%E3%83%91%E3%82%A4%E3%83%AB%E3%81%A8%E3%81%AF\">JITコンパイルとは</a></li>\n<li><a href=\"#%E3%83%A1%E3%83%A2%E3%83%AA%E3%81%AE%E7%AF%80%E7%B4%84%E4%BE%8B\">メモリの節約例</a></li>\n<li><a href=\"#%E5%8F%82%E8%80%83\">参考</a></li>\n</ul>","excerpt":"こんにちは．今回は，PyTorchでサポートされているTorchScriptへの変換を\n行うJITコンパイル機能が，GPUのメモリの節約になる例を紹介したいと思います． JITコンパイルとは JITはJust In Timeの略です． JIT…","frontmatter":{"title":"TorchScript(torch.jit)でGPUメモリを節約する","date":"2022.05.30","update":"2022.05.30","category":"PyTorch","tags":["Python","PyTorch"]},"fields":{"slug":"/posts/2022-05-30-torch-jit/"}}},"pageContext":{"id":"b32445d1-147f-517f-b0b1-c0660f12fc59"}},"staticQueryHashes":["1123391092"],"slicesMap":{}}