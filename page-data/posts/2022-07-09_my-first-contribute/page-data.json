{"componentChunkName":"component---src-templates-post-js","path":"/posts/2022-07-09_my-first-contribute/","result":{"data":{"site":{"siteMetadata":{"title":"MJUN Tech Note","author":"Junya Morioka"}},"markdownRemark":{"id":"2a870dc3-35a8-5cc1-a573-b0d4148e14f5","html":"<p>こんにちは．今回は私が初めて立てたissueがPyTorchのバグを修正に繋がり，\n新しいCI/CDテスト項目を増やすに至った話と，\nこのバグをもとに初めてのPull RequestをYOLOv5に送ってcontributerになった話を\n書きたいと思います．</p>\n<p>個人的な話になりますが，大きなOSSに貢献するのは初めてなので，\n記録に残して，OSSに貢献する流れが伝わればと思い書くことにします．</p>\n<h2 id=\"事の経緯\">事の経緯</h2>\n<p>普段，深層学習手法の実装にPyTorchを利用しているのですが，\n使用するGPUの切り替えを以下のようなコードで行っていました．</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> torch\n\nos<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">\"CUDA_DEVICE_ORDER\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"PCI_BUS_ID\"</span>\nos<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">\"CUDA_VISIBLE_DEVICES\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"1\"</span>\n\n<span class=\"token comment\"># print using GPU Info</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Using GPU is CUDA:</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>os<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">'CUDA_VISIBLE_DEVICES'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>device_count<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    info <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>get_device_properties<span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"CUDA:</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>i<span class=\"token punctuation\">}</span></span><span class=\"token string\"> </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>info<span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">}</span></span><span class=\"token string\">, </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>info<span class=\"token punctuation\">.</span>total_memory <span class=\"token operator\">/</span> <span class=\"token number\">1024</span> <span class=\"token operator\">**</span> <span class=\"token number\">2</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">MB\"</span></span><span class=\"token punctuation\">)</span>\n\ndevice <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>device<span class=\"token punctuation\">(</span><span class=\"token string\">\"cuda:0\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>上記のコードではPyTorchでGPU割り当てに，\n環境変数<code class=\"language-text\">CUDA_VISIBLE_DEVICES</code>を使用しています．\nこうすることで，実行プロセス内で指定したGPU以外をマスクすることができるので，\n安全にリソースを扱えます．(例えばコード上でどこでも<code class=\"language-text\">cuda:0</code>を書いても安全)</p>\n<p>PyTorchでは<code class=\"language-text\">torch.cuda</code>モジュールが呼び出されるまではCUDA Deviceの初期化は\n行われないので，環境変数をコード上で変更したあとに<code class=\"language-text\">touch.cuda</code>を呼び出せば，\n環境変数が適用されます．(いわゆるlazy load)</p>\n<p>環境変数なので，実行時にも<code class=\"language-text\">CUDA_VISIBLE_DEVICES=0 python train.py</code>というように指定できます．</p>\n<p>このコードがPyTorch Version 1.11.0までは動いていたのですが，\n1.12.0から動かなくなってしまいました．</p>\n<p>具体的な例をあげます．\n以下のような計算機があったとします．</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">CUDA:0 NVIDIA RTX A6000, <span class=\"token number\">48685</span>.3125MB\nCUDA:1 NVIDIA GeForce RTX <span class=\"token number\">3090</span>, <span class=\"token number\">24268</span>.3125MB</code></pre></div>\n<p>この計算機でCUDA:1のRTX 3090を使いたいと考え，\n上記のコードをVer 1.12.0と1.11.0で動かします．\nすると出力は以下のようになります．</p>\n<ul>\n<li>Ver 1.11</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">Using GPU is CUDA:1\nCUDA:0 NVIDIA GeForce RTX <span class=\"token number\">3090</span>, <span class=\"token number\">24268</span>.3125MB</code></pre></div>\n<ul>\n<li>Ver 1.12</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">Using GPU is CUDA:1\nCUDA:0 NVIDIA RTX A6000, <span class=\"token number\">48685</span>.3125MB\nCUDA:1 NVIDIA GeForce RTX <span class=\"token number\">3090</span>, <span class=\"token number\">24268</span>.3125MB</code></pre></div>\n<p>上記の通り，Ver 1.12ではコード上で書き換えた<code class=\"language-text\">CUDA_VISIBLE_DEVICES</code>の環境変数が\n適用されていないことがわかります．</p>\n<p>私はこの方法でGPUの割当を行っていたのでとても困りました．</p>\n<h2 id=\"yolov5のissue\">YOLOv5のIssue</h2>\n<p>物体検出手法である<a href=\"https://github.com/ultralytics/yolov5\">YOLOv5</a>は\nPyTorchで実装されています．YOLOv５も同じような方法でGPUの割当を行っていたのを\n思い出したので，YOLOv5で同じような問題が起きていないかIssueを探すことにしました．</p>\n<p>すると，リポジトリのAuthorであるGlenn Jocher氏が以下のようなIssueを\n上げていました．</p>\n<p><a href=\"https://github.com/ultralytics/yolov5/issues/8395\">YOLOv5 issues with torch==1.12 on Multi-GPU systems</a></p>\n<p>まさしく，私と同じ問題を抱えていました．\nそこで，問題を再現可能な小さいコードを示しました．</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> torch\n\nos<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">\"CUDA_DEVICE_ORDER\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"PCI_BUS_ID\"</span>\nos<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">\"CUDA_VISIBLE_DEVICES\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"1\"</span>\n\n<span class=\"token comment\"># print using GPU Info</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Using GPU is CUDA:</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>os<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">'CUDA_VISIBLE_DEVICES'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>device_count<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    info <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>get_device_properties<span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"CUDA:</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>i<span class=\"token punctuation\">}</span></span><span class=\"token string\"> </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>info<span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">}</span></span><span class=\"token string\">, </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>info<span class=\"token punctuation\">.</span>total_memory <span class=\"token operator\">/</span> <span class=\"token number\">1024</span> <span class=\"token operator\">**</span> <span class=\"token number\">2</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">MB\"</span></span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>そして，以下のように<code class=\"language-text\">import torch</code>の前に環境変数を指定すれば\n上手く動作することもわかりました．</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n\nos<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">\"CUDA_DEVICE_ORDER\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"PCI_BUS_ID\"</span>\nos<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">\"CUDA_VISIBLE_DEVICES\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"1\"</span>\n\n<span class=\"token keyword\">import</span> torch</code></pre></div>\n<p>その後も<code class=\"language-text\">importlib</code>を使ったモジュールのreload等を試しましたが問題は解決せず，\nこれはPyTorch自体の問題であると考え，PyTorchに人生初のIssueを投稿することにしました．</p>\n<h2 id=\"pytorchのissue\">PyTorchのIssue</h2>\n<p>私がPyTorchのリポジトリに投稿したIssueは以下です．</p>\n<p><a href=\"https://github.com/pytorch/pytorch/issues/80876\">[1.12] os.environ[\"CUDA_VISIBLE_DEVICES\"] has no effect</a></p>\n<p>投稿したところ，この問題が<code class=\"language-text\">high priority</code>に指定されたため，とても緊張した覚えがあります．</p>\n<p>PyTorchのMain Contributerとやり取りする中で，この問題を再現できる人とできない人がいたため，\n再現しやすいようにDockerfileの例を出しながら，どのような場合に問題が起きるかを調査しました．</p>\n<p>最終的に，この問題を発生させる最小コードは以下のようになりました．</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> torch\n\nos<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">\"CUDA_VISIBLE_DEVICES\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"32\"</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>__version__<span class=\"token punctuation\">,</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>device_count<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># ver 1.11</span>\n$ python cudev.py \n<span class=\"token number\">1.11</span>.0+cu113 <span class=\"token number\">0</span>\n\n<span class=\"token comment\"># ver 1.12</span>\n$ python3 cudev.py\n<span class=\"token number\">1.12</span>.0+cu113 <span class=\"token number\">7</span></code></pre></div>\n<p><code class=\"language-text\">CUDA_VISIBLE_DEVICES</code>を32というありえない数字にすることで，\nGPUの割当を0にする試みです．このコードも1.12では期待した動作をしませんでした．</p>\n<p>すると，Contributorであるmalfet氏が\n<a href=\"https://github.com/pytorch/pytorch/issues/80876#issuecomment-1175359856\">問題の原因を発見</a>しました．</p>\n<p>ver 1.11から1.12までのcommitで，<code class=\"language-text\">import torch</code>でモジュールを読み込むまでの間に\n<code class=\"language-text\">torch.cuda</code>を呼び出している箇所があり，これが原因でCUDA Deviceの初期化が意図せず\n行われていることがわかりました．一度CUDA Deviceの初期化が行われると\n再度初期化を行うことはできないので，<code class=\"language-text\">torch.cuda</code>を呼び出さないように修正されました．</p>\n<p>そして，この問題が再発しないように，\nPyTorchのテスト項目として，以下のコードが追記されました．</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token decorator annotation punctuation\">@unittest<span class=\"token punctuation\">.</span>skipIf</span><span class=\"token punctuation\">(</span>TEST_WITH_ROCM<span class=\"token punctuation\">,</span> <span class=\"token string\">\"ROCm doesn't support CUDA_VISIBLE_DEVICES\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token decorator annotation punctuation\">@unittest<span class=\"token punctuation\">.</span>skipIf</span><span class=\"token punctuation\">(</span>TEST_MULTIGPU<span class=\"token punctuation\">,</span> <span class=\"token string\">\"Testing on one GPU is sufficient\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">test_lazy_init</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\" Validate that no CUDA calls are made during `import torch` call\"\"\"</span>\n    <span class=\"token keyword\">from</span> subprocess <span class=\"token keyword\">import</span> check_output\n    test_script <span class=\"token operator\">=</span> <span class=\"token string\">\"import os; import torch;os.environ['CUDA_VISIBLE_DEVICES']='32';print(torch.cuda.device_count())\"</span>\n    rc <span class=\"token operator\">=</span> check_output<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>sys<span class=\"token punctuation\">.</span>executable<span class=\"token punctuation\">,</span> <span class=\"token string\">'-c'</span><span class=\"token punctuation\">,</span> test_script<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span><span class=\"token string\">\"ascii\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    self<span class=\"token punctuation\">.</span>assertEqual<span class=\"token punctuation\">(</span>rc<span class=\"token punctuation\">,</span> <span class=\"token string\">\"0\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>この修正はPyTorch Version 1.12.1で適用される予定です．</p>\n<h2 id=\"yolov5にpull-request\">YOLOv5にPull Request</h2>\n<p>PyTorchに投稿したIssueを踏まえて，\nこの問題をYOLOv5のコード内で解決することは難しそうでしたが，\nPyTorchの次期バージョンで修正されることがわかりました．</p>\n<p>そのため，YOLOv5のリポジトリにある<code class=\"language-text\">requirements.txt</code>に以下の変更を加えて\n修正するPull Requestを贈りました．</p>\n<div class=\"gatsby-highlight\" data-language=\"diff\"><pre class=\"language-diff\"><code class=\"language-diff\"><span class=\"token deleted-sign deleted\"><span class=\"token prefix deleted\">-</span> torch>=1.7.0\n<span class=\"token prefix deleted\">-</span> torchvision>=0.8.1\n</span>\n<span class=\"token inserted-sign inserted\"><span class=\"token prefix inserted\">+</span> torch>=1.7.0,!=1.12.0  # https://github.com/ultralytics/yolov5/issues/8395\n<span class=\"token prefix inserted\">+</span> torchvision>=0.8.1,!=0.13.0 # https://github.com/ultralytics/yolov5/issues/8395</span></code></pre></div>\n<p>この問題は特定のバージョンのPyTorchで起こり，将来の1.12.1で修正されるので，\nVer 1.12と対応するtorchvisionのバージョンを除外することで問題を解決することにしました．</p>\n<p>このPull Requestは無事mergeされ，私は初めてOSSにPull Requestを送ってmergeされました．</p>\n<h2 id=\"まとめ\">まとめ</h2>\n<p>初めてのIssue, Pull Requestだったため，先人のサイトを読みながら慎重に\nやり取りを進めました．</p>\n<p>PyTorchのContributorがreproと言って気にしていたように，\nIssue報告をする際は問題を再現する最小のコードを提供することが大切であると\n痛感しました．これは普段の開発でも大切なことです．</p>\n<p>下世話な話ですが，先にPyTorchの問題箇所を発見できていれば\nPyTorchのContributorになれたのに...なんて思ったりしました．</p>\n<p>以上，PyTorchとYOLOv5に貢献した話でした．</p>","tableOfContents":"<ul>\n<li><a href=\"#%E4%BA%8B%E3%81%AE%E7%B5%8C%E7%B7%AF\">事の経緯</a></li>\n<li><a href=\"#yolov5%E3%81%AEissue\">YOLOv5のIssue</a></li>\n<li><a href=\"#pytorch%E3%81%AEissue\">PyTorchのIssue</a></li>\n<li><a href=\"#yolov5%E3%81%ABpull-request\">YOLOv5にPull Request</a></li>\n<li><a href=\"#%E3%81%BE%E3%81%A8%E3%82%81\">まとめ</a></li>\n</ul>","excerpt":"こんにちは．今回は私が初めて立てたissueがPyTorchのバグを修正に繋がり，\n新しいCI/CDテスト項目を増やすに至った話と，\nこのバグをもとに初めてのPull RequestをYOLOv5に送ってcontributer…","frontmatter":{"title":"初めてのissueとPull ReqでPyTorchとYOLOv5に貢献した話","date":"2022.07.11","update":"2022.07.11","category":"Dev","tags":["PyTorch","Github"]},"fields":{"slug":"/posts/2022-07-09_my-first-contribute/"}}},"pageContext":{"id":"2a870dc3-35a8-5cc1-a573-b0d4148e14f5"}},"staticQueryHashes":["1123391092"],"slicesMap":{}}