<!DOCTYPE html><html lang="ja"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta data-react-helmet="true" name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1, user-scalable=yes"/><meta data-react-helmet="true" name="twitter:image" content="https://note.mjunya.com/ogp_image_square.png"/><meta data-react-helmet="true" name="twitter:description" content="機械学習ライブラリの PyTorch には、複数のマシン・GPU で
学習を行う方法がいくつか用意されている。 この記事を書いている現在、PyTorch の stable version は 1.11.0 であるが、
実行方法が、直近の version 1.9.0 と 1.1…"/><meta data-react-helmet="true" name="twitter:title" content="PyTorchのMultiGPUの概要 【DataParallel, DistributedDataParallel, torchrun】 | MJUN Tech Note"/><meta data-react-helmet="true" name="twitter:card" content="summary"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:description" content="機械学習ライブラリの PyTorch には、複数のマシン・GPU で
学習を行う方法がいくつか用意されている。 この記事を書いている現在、PyTorch の stable version は 1.11.0 であるが、
実行方法が、直近の version 1.9.0 と 1.1…"/><meta data-react-helmet="true" property="og:locale" content="ja_JP"/><meta data-react-helmet="true" property="og:image" content="https://note.mjunya.com/ogp_image_square.png"/><meta data-react-helmet="true" property="og:site_name" content="MJUN Tech Note"/><meta data-react-helmet="true" property="og:url" content="https://note.mjunya.com/posts/2022-04-18-torchrun/"/><meta data-react-helmet="true" property="og:title" content="PyTorchのMultiGPUの概要 【DataParallel, DistributedDataParallel, torchrun】 | MJUN Tech Note"/><meta data-react-helmet="true" name="description" content="機械学習ライブラリの PyTorch には、複数のマシン・GPU で
学習を行う方法がいくつか用意されている。 この記事を書いている現在、PyTorch の stable version は 1.11.0 であるが、
実行方法が、直近の version 1.9.0 と 1.1…"/><meta data-react-helmet="true" charSet="utf-8"/><meta name="generator" content="Gatsby 4.11.2"/><style data-href="/styles.f22ca4e33d8907f4a55d.css" data-identity="gatsby-global-css">@import url(https://fonts.googleapis.com/css2?family=Roboto+Mono&display=swap);@import url(https://fonts.googleapis.com/css2?family=Raleway&display=swap);code[class*=language-],pre[class*=language-]{word-wrap:normal;background:none;border-radius:15px;color:#abb2bf;font-family:Roboto Mono,SFMono-Regular,Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none;-o-tab-size:4;tab-size:4;text-align:left;white-space:pre;word-break:normal;word-spacing:normal}code[class*=language-] ::selection,code[class*=language-]::selection,pre[class*=language-] ::selection,pre[class*=language-]::selection{background:#9aa2b1;text-shadow:none}@media print{code[class*=language-],pre[class*=language-]{text-shadow:none}}pre[class*=language-]{margin:.5em 0;overflow:auto;padding:1em}:not(pre)>code[class*=language-],pre[class*=language-]{background:#282c34}:not(pre)>code[class*=language-]{border-radius:.3em;padding:.1em;white-space:normal}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#5c6370}.token.punctuation{color:#abb2bf}.namespace{opacity:.7}.token.boolean,.token.constant,.token.deleted,.token.number,.token.property,.token.symbol,.token.tag{color:#d19a66}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#98c379}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url{color:#56b6c2}.token.atrule,.token.attr-value,.token.keyword{color:#c678dd}.token.class-name,.token.function{color:#61afef}.token.important,.token.regex{color:#c678dd}.token.variable{color:#e06c75}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}pre[data-line]{padding:1em 0 1em 3em;position:relative}.line-highlight{background:hsla(24,20%,50%,.08);background:linear-gradient(90deg,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));left:0;line-height:inherit;margin-top:1em;padding-bottom:inherit;padding-left:0;padding-right:0;padding-top:inherit;pointer-events:none;position:absolute;right:0;white-space:pre}.line-highlight:before,.line-highlight[data-end]:after{background-color:hsla(24,20%,50%,.4);border-radius:999px;box-shadow:0 1px #fff;color:#f5f2f0;content:attr(data-start);font:700 65%/1.5 sans-serif;left:.6em;min-width:1em;padding:0 .5em;position:absolute;text-align:center;text-shadow:none;top:.4em;vertical-align:.3em}.line-highlight[data-end]:after{bottom:.4em;content:attr(data-end);top:auto}.line-numbers .line-highlight:after,.line-numbers .line-highlight:before{content:none}pre[class*=language-].line-numbers{counter-reset:linenumber;padding-left:3.8em;position:relative}pre[class*=language-].line-numbers>code{position:relative;white-space:inherit}.line-numbers .line-numbers-rows{border-right:1px solid #999;font-size:100%;left:-3.8em;letter-spacing:-1px;pointer-events:none;position:absolute;top:-2px;-webkit-user-select:none;-ms-user-select:none;user-select:none;width:3em}.line-numbers-rows>span{counter-increment:linenumber;display:block;pointer-events:none}.line-numbers-rows>span:before{color:#999;content:counter(linenumber);display:block;padding-right:.8em;text-align:right}div.code-toolbar{position:relative;width:100%}div.code-toolbar>.toolbar{opacity:0;position:absolute;right:.2em;top:.2em;transition:opacity .3s ease-in-out}div.code-toolbar:hover>.toolbar{opacity:1}div.code-toolbar>.toolbar .toolbar-item{display:inline-block}div.code-toolbar>.toolbar a{cursor:pointer}div.code-toolbar>.toolbar button{background:none;border:0;color:inherit;font:inherit;line-height:normal;overflow:visible;padding:0;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none}div.code-toolbar>.toolbar a,div.code-toolbar>.toolbar button,div.code-toolbar>.toolbar span{background:#f5f2f0;background:hsla(0,0%,88%,.2);border-radius:.5em;box-shadow:0 2px 0 0 rgba(0,0,0,.2);color:#bbb;font-size:.6em;padding:0 .5em}div.code-toolbar>.toolbar a:focus,div.code-toolbar>.toolbar a:hover,div.code-toolbar>.toolbar button:focus,div.code-toolbar>.toolbar button:hover,div.code-toolbar>.toolbar span:focus,div.code-toolbar>.toolbar span:hover{color:inherit;text-decoration:none}[class*=lang-] script[type="text/plain"],[class*=language-] script[type="text/plain"],script[type="text/plain"][class*=lang-],script[type="text/plain"][class*=language-]{display:block;font:100% Fira Code,Consolas,Monaco,monospace;overflow:auto;white-space:pre}.command-line-prompt{border-right:1px solid #999;display:block;float:left;font-size:100%;letter-spacing:-1px;margin-right:1em;pointer-events:none;-webkit-user-select:none;-ms-user-select:none;user-select:none}.command-line-prompt>span:before{color:#999;content:" ";display:block;padding-right:.8em}.command-line-prompt>span[data-user]:before{content:"[" attr(data-user) "@" attr(data-host) "] $"}.command-line-prompt>span[data-user=root]:before{content:"[" attr(data-user) "@" attr(data-host) "] #"}.command-line-prompt>span[data-prompt]:before{content:attr(data-prompt)}nav{margin-top:auto}nav ul{list-style:none!important;text-align:right}nav ul li{display:inline-block}nav a,nav a:visited{color:var(--text-color);font-size:.8rem;font-weight:500;letter-spacing:.05em;margin:.5rem;text-decoration:none;text-transform:uppercase}@media screen and (max-width:480px){nav{margin-top:0}nav ul{text-align:left}nav a,nav a:visited{font-size:1rem}}.toggleThemeButton-module--toggleButton--qiKzv{color:var(--text-color);height:1.2em;margin-left:.25em;margin-right:.25em;vertical-align:middle;width:auto}header{align-items:center;color:var(--accent-color);display:flex;display:-webkit-flex;font-display:swap;font-family:Raleway,Inter,Helvetica,Helvetica Neue,Arial,Hiragino Kaku Gothic ProN,Hiragino Sans,Meiryo,sans-serif;justify-content:space-between;padding:.5rem 2rem}.header-module--siteTitle--rCCDh{border:1px solid var(--accent-color);font-size:1.5rem;font-weight:200;margin-bottom:0;margin-top:.5rem;padding:.5rem;word-break:normal}.header-module--siteTitle--rCCDh a,.header-module--siteTitle--rCCDh a:visited{color:var(--accent-color);text-decoration:none}.header-module--siteTitle--rCCDh a,.header-module--siteTitle--rCCDh a:visited,.profile-module--profile--bfKTr{font-family:Raleway,Inter,Helvetica,Helvetica Neue,Arial,Hiragino Kaku Gothic ProN,Hiragino Sans,Meiryo,sans-serif}.profile-module--profile--bfKTr{background-color:var(--card-color);border:1px solid var(--shadow-color);border-radius:15px;padding:1rem;text-align:center}svg{vertical-align:text-top}.profile-module--profileDescription--bZ8LE{font-size:.9em}.profile-module--profileIcon--p9rny{border-radius:50%}.profile-module--profileIconWrapper--7H\+Py{max-width:60%}.profile-module--iconLink--IVBRi{color:var(--text-color);margin-right:.2em}.profile-module--iconLink--IVBRi svg{height:1.5em;width:auto}body{--background-color:#161718;--card-color:#232227;--shadow-color:#232227;--text-color:#adadad;--accent-color:#1d71d7;background-color:var(--background-color);color:var(--text-color);font-display:swap;font-family:Helvetica Neue,Arial,Hiragino Kaku Gothic ProN,Hiragino Sans,Meiryo,sans-serif;margin:auto;max-width:90rem}body.is_inverted{--background-color:#f9f9f9;--card-color:#fff;--shadow-color:#d3d3d3;--text-color:#212121;--accent-color:#1d71d7}.container{display:flex;display:-webkit-flex}.main{max-width:75%;width:75%}.main,.sidebar{padding:.5rem 1rem}.sidebar{display:flex;flex-direction:column;min-width:20%;width:20%}@media screen and (max-width:480px){.container{flex-direction:column-reverse}.main,.sidebar{width:auto}}.skill-module--skillList--IZiAE{list-style:none;margin:.5em 0;padding:0}.skill-module--skillIcon--W08p2{color:var(--text-color);height:1.2em;margin-right:.25em;vertical-align:middle;width:auto}.skill-module--skillText--7Cre6{font-size:1.2em}.skill-module--skillContainer--fbprk{display:flex;flex-wrap:wrap}.skill-module--skillColumn--U6pNT{width:100%}@media(min-width:480px){.skill-module--skillColumn--U6pNT{width:50%}}.static-module--main--yDpCl{background-color:var(--card-color);border:1px solid var(--shadow-color);padding:1.5rem}.static-module--main--yDpCl h1{color:var(--accent-color)}.static-module--main--yDpCl ul{-webkit-padding-start:1em;padding-inline-start:1em}.static-module--iconLink--zhBNi{color:var(--text-color);margin-right:.2em}.static-module--iconLink--zhBNi svg{height:2em;width:auto}.static-module--profileIconWrapper--O4naF{max-width:20%}.static-module--profileIcon--9pd6b{border-radius:50%}.static-module--aboutMain--0z24d{background-color:var(--card-color);border:1px solid var(--shadow-color);padding:1.5rem}.static-module--aboutMain--0z24d h1{color:var(--accent-color)}.static-module--aboutMain--0z24d h1,.static-module--aboutMain--0z24d h2,.static-module--aboutMain--0z24d h3{font-family:Raleway,Inter,Helvetica,Helvetica Neue,Arial,Hiragino Kaku Gothic ProN,Hiragino Sans,Meiryo,sans-serif}.static-module--aboutMain--0z24d h2,.static-module--aboutMain--0z24d h3{margin:.2em}.static-module--aboutMain--0z24d h2{color:var(--accent-color)}.static-module--aboutMain--0z24d .static-module--twitter--mBSC9{color:var(--accent-color);text-decoration:none}.static-module--link--5nV6T{color:var(--text-color);text-decoration:none}.static-module--link--5nV6T:hover{text-decoration:underline}.postcardList-module--grid--EdfIK{grid-gap:1rem;display:grid;grid-template-columns:1fr}.postcardList-module--postcard--7c4Q9{align-items:left;background:var(--card-color);border:1px solid var(--shadow-color);border-radius:10px;display:flex;flex-direction:column;justify-content:left;margin:0 1rem;min-height:5rem;padding:0 1.5rem 1.5rem;position:relative;transition:all .3s cubic-bezier(.25,.45,.45,.95)}.postcardList-module--postcard--7c4Q9:hover{-webkit-transform:scale(1.02);transform:scale(1.02)}.postcardList-module--postcard--7c4Q9 h2{font-size:1.3em;margin-bottom:.5em}.postcardList-module--postcardTitle---SY0n{color:var(--accent-color);text-decoration:none}.postcardList-module--postcardCategory--Pqtam{margin-left:3rem}.postcardList-module--postMeta--qBM49{margin-left:2em}svg{height:.5em}.postcardList-module--categoryLink--Kp9oB{color:var(--text-color);text-decoration:none}.postcardList-module--categoryLink--Kp9oB:hover{text-decoration:underline}.pagination-module--pagination--mggr1{align-items:center;display:flex;font-family:Raleway,Inter,Helvetica,Helvetica Neue,Arial,Hiragino Kaku Gothic ProN,Hiragino Sans,Meiryo,sans-serif;justify-content:space-between;padding:1.3rem}.pagination-module--pagination--mggr1 a,.pagination-module--pagination--mggr1 a:visited{color:var(--text-color);font-size:.8rem;font-weight:500;letter-spacing:.05em;margin:.5rem;text-decoration:none;text-transform:uppercase}.CategoryList-module--tocRoot--mPpT8{background-color:var(--card-color);border:1px solid var(--shadow-color);border-radius:15px;font-family:Raleway,Inter,Helvetica,Helvetica Neue,Arial,Hiragino Kaku Gothic ProN,Hiragino Sans,Meiryo,sans-serif;font-size:.9em;margin-top:1rem;position:-webkit-sticky;position:sticky;top:2rem}.CategoryList-module--tocItem--3gpWN{list-style:none;padding-left:2em;padding-right:.5em}.CategoryList-module--tocItem--3gpWN li a,.CategoryList-module--tocItem--3gpWN li a:visited{color:var(--text-color);text-decoration:none;text-transform:uppercase}.CategoryList-module--tocItem--3gpWN li a:hover{background-color:var(--shadow-color)}@media screen and (max-width:480px){.CategoryList-module--tocRoot--mPpT8{display:none}}.tableOfContents-module--tocRoot--t6LR\+{background-color:var(--card-color);border:1px solid var(--shadow-color);border-radius:15px;font-family:Raleway,Inter,Helvetica,Helvetica Neue,Arial,Hiragino Kaku Gothic ProN,Hiragino Sans,Meiryo,sans-serif;font-size:.9em;margin-top:1rem;position:-webkit-sticky;position:sticky;top:2rem}.tableOfContents-module--tocItem--MZysC{padding-left:2em;padding-right:.5em}.tableOfContents-module--tocItem--MZysC li a,.tableOfContents-module--tocItem--MZysC li a:visited{color:var(--text-color);text-decoration:none;text-transform:uppercase}.tableOfContents-module--tocItem--MZysC li a:hover{background-color:var(--shadow-color)}@media screen and (max-width:480px){.tableOfContents-module--tocRoot--t6LR\+{display:none}}.post-module--postMain--oWbD\+{background-color:var(--card-color);border:1px solid var(--shadow-color);border-radius:15px;padding:1rem}.post-module--postTitle--eWkbD{color:var(--accent-color);font-size:1.8rem}.post-module--postMetas--mQGzs{list-style-type:none;margin-bottom:1.5em;padding:0}.post-module--postMetas--mQGzs li{display:inline;margin-right:1rem}@media screen and (max-width:480px){.post-module--postMetas--mQGzs li{display:block}}.post-module--postMeta--t\+-D\+{font-family:Raleway,Inter,Helvetica,Helvetica Neue,Arial,Hiragino Kaku Gothic ProN,Hiragino Sans,Meiryo,sans-serif}.post-module--link--T97u1{color:var(--text-color);text-decoration:none}.post-module--link--T97u1:hover{text-decoration:underline}svg{height:1em;vertical-align:middle;width:auto}.post-module--markdown--o91q7 h1,.post-module--markdown--o91q7 h2,.post-module--markdown--o91q7 h3,.post-module--markdown--o91q7 h4,.post-module--markdown--o91q7 h5,.post-module--markdown--o91q7 h6{font-weight:600;line-height:1.25;margin-bottom:16px;margin-top:24px}.post-module--markdown--o91q7 h1,.post-module--markdown--o91q7 h2{border-bottom:1px solid var(--shadow-color);font-weight:600;padding-bottom:.3em}.post-module--markdown--o91q7 h1{font-size:1.5em;margin:.67em 0}.post-module--markdown--o91q7 h2{font-size:1.2em}.post-module--markdown--o91q7 h3{font-size:1.25em}.post-module--markdown--o91q7 h4{font-size:1em}.post-module--markdown--o91q7 h5{font-size:.875em}.post-module--markdown--o91q7 h6{font-size:.85em}.post-module--markdown--o91q7 a{color:#0366d6;text-decoration:none;word-break:break-all}.post-module--markdown--o91q7 a:hover{text-decoration:underline}.post-module--markdown--o91q7 blockquote,.post-module--markdown--o91q7 ol,.post-module--markdown--o91q7 p,.post-module--markdown--o91q7 pre,.post-module--markdown--o91q7 table,.post-module--markdown--o91q7 ul{margin-bottom:16px;margin-top:0}.post-module--markdown--o91q7 blockquote{border-left:.25em solid #dfe2e5;color:#6a737d;padding:0 1em}.post-module--markdown--o91q7 blockquote>:first-child{margin-top:0}.post-module--markdown--o91q7 blockquote>:last-child{margin-bottom:0}.post-module--markdown--o91q7 table{border-collapse:collapse;border-spacing:0;display:block;overflow:auto;width:100%}.post-module--markdown--o91q7 table tr{background-color:#fff;border-top:1px solid #c6cbd1}.post-module--markdown--o91q7 table tr:nth-child(2n){background-color:#f6f8fa}.post-module--markdown--o91q7 table th{font-weight:600}.post-module--markdown--o91q7 table td,.post-module--markdown--o91q7 table th{border:1px solid #dfe2e5;padding:6px 13px}.post-module--markdown--o91q7 code[class=language-text]{background:var(--shadow-color)!important;color:var(--text-color)}</style><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper picture.object-fit-polyfill{position:static!important}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){if(void 0===e.target.dataset.mainImage)return;if(void 0===e.target.dataset.gatsbyImageSsr)return;const t=e.target;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script><title data-react-helmet="true">PyTorchのMultiGPUの概要 【DataParallel, DistributedDataParallel, torchrun】 | MJUN Tech Note</title><link data-react-helmet="true" rel="canonical" href="URL"/><link data-react-helmet="true" rel="icon" href="/favicon.ico"/><link data-react-helmet="true" rel="apple-touch-icon" sizes="1024x1024" href="/icon.png"/><link rel="sitemap" type="application/xml" href="/sitemap/sitemap-index.xml"/><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><script>window.dataLayer = window.dataLayer || [];window.dataLayer.push({"platform":"gatsby"}); (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= 'https://www.googletagmanager.com/gtm.js?id='+i+dl+'';f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer', 'GTM-N3DMFDC');</script><link rel="alternate" type="application/rss+xml" title="MJUN Tech Note RSS Feed" href="/rss.xml"/><link as="script" rel="preload" href="/webpack-runtime-383a21dce55454d79a33.js"/><link as="script" rel="preload" href="/framework-e9e354935324f36f552a.js"/><link as="script" rel="preload" href="/app-fb1898ca3cc5ab8fa7a6.js"/><link as="script" rel="preload" href="/commons-57e03994e03942ac0f58.js"/><link as="script" rel="preload" href="/component---src-templates-post-js-f819aabdc660afd8ccb6.js"/><link as="fetch" rel="preload" href="/page-data/posts/2022-04-18-torchrun/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/1123391092.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N3DMFDC" height="0" width="0" style="display: none; visibility: hidden" aria-hidden="true"></iframe></noscript><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div><header role="banner"><h1 class="header-module--siteTitle--rCCDh"><a href="/">MJUN Tech Note</a></h1><nav role="navigation"><ul><li><a href="/">Home</a></li><li><a href="/categories/">Categories</a></li><li><a href="/tags/">Tags</a></li><li><a href="/about/">About Me</a></li><li><a href="/rss.xml">Feed</a></li><li><div><svg class="toggleThemeButton-module--toggleButton--qiKzv" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M512 256C512 397.4 397.4 512 256 512C114.6 512 0 397.4 0 256C0 114.6 114.6 0 256 0C397.4 0 512 114.6 512 256zM256 64V448C362 448 448 362 448 256C448 149.1 362 64 256 64z"></path></svg></div></li></ul></nav></header><div class="container"><div class="sidebar"><div class="profile-module--profile--bfKTr"><div data-gatsby-image-wrapper="" class="gatsby-image-wrapper gatsby-image-wrapper-constrained profile-module--profileIconWrapper--7H+Py"><div style="max-width:358px;display:block"><img alt="" role="presentation" aria-hidden="true" src="data:image/svg+xml;charset=utf-8,%3Csvg height=&#x27;358&#x27; width=&#x27;358&#x27; xmlns=&#x27;http://www.w3.org/2000/svg&#x27; version=&#x27;1.1&#x27;%3E%3C/svg%3E" style="max-width:100%;display:block;position:static"/></div><div aria-hidden="true" data-placeholder-image="" style="opacity:1;transition:opacity 500ms linear;background-color:#c8d888;position:absolute;top:0;left:0;bottom:0;right:0"></div><picture><source type="image/webp" srcSet="/static/15ba60a9b462b90372f583a49016a90d/5d191/profile-icon.webp 90w,/static/15ba60a9b462b90372f583a49016a90d/84361/profile-icon.webp 179w,/static/15ba60a9b462b90372f583a49016a90d/3acea/profile-icon.webp 358w" sizes="(min-width: 358px) 358px, 100vw"/><img data-gatsby-image-ssr="" class="profile-module--profileIcon--p9rny" data-main-image="" style="opacity:0" sizes="(min-width: 358px) 358px, 100vw" decoding="async" loading="eager" src="/static/15ba60a9b462b90372f583a49016a90d/de250/profile-icon.png" srcSet="/static/15ba60a9b462b90372f583a49016a90d/25ed1/profile-icon.png 90w,/static/15ba60a9b462b90372f583a49016a90d/ad96b/profile-icon.png 179w,/static/15ba60a9b462b90372f583a49016a90d/de250/profile-icon.png 358w" alt="profile image"/></picture><noscript><picture><source type="image/webp" srcSet="/static/15ba60a9b462b90372f583a49016a90d/5d191/profile-icon.webp 90w,/static/15ba60a9b462b90372f583a49016a90d/84361/profile-icon.webp 179w,/static/15ba60a9b462b90372f583a49016a90d/3acea/profile-icon.webp 358w" sizes="(min-width: 358px) 358px, 100vw"/><img data-gatsby-image-ssr="" class="profile-module--profileIcon--p9rny" data-main-image="" style="opacity:0" sizes="(min-width: 358px) 358px, 100vw" decoding="async" loading="eager" src="/static/15ba60a9b462b90372f583a49016a90d/de250/profile-icon.png" srcSet="/static/15ba60a9b462b90372f583a49016a90d/25ed1/profile-icon.png 90w,/static/15ba60a9b462b90372f583a49016a90d/ad96b/profile-icon.png 179w,/static/15ba60a9b462b90372f583a49016a90d/de250/profile-icon.png 358w" alt="profile image"/></picture></noscript><script type="module">const t="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;if(t){const t=document.querySelectorAll("img[data-main-image]");for(let e of t){e.dataset.src&&(e.setAttribute("src",e.dataset.src),e.removeAttribute("data-src")),e.dataset.srcset&&(e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset"));const t=e.parentNode.querySelectorAll("source[data-srcset]");for(let e of t)e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset");e.complete&&(e.style.opacity=1)}}</script></div><h3>Junya Morioka</h3><p><a href="https://github.com/mjun0812" class="profile-module--iconLink--IVBRi"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" class="svg-inline--fa fa-github fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a href="https://twitter.com/mjun0812" class="profile-module--iconLink--IVBRi"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" class="svg-inline--fa fa-github fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a></p><p><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="map-marker-alt" class="svg-inline--fa fa-map-marker-alt fa-w-12" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" width="32" height="32"><path fill="currentColor" d="M172.268 501.67C26.97 291.031 0 269.413 0 192 0 85.961 85.961 0 192 0s192 85.961 192 192c0 77.413-26.97 99.031-172.268 309.67-9.535 13.774-29.93 13.773-39.464 0zM192 272c44.183 0 80-35.817 80-80s-35.817-80-80-80-80 35.817-80 80 35.817 80 80 80z"></path></svg>Tokyo, Japan<!-- --></p><p class="profile-module--profileDescription--bZ8LE">Computer VisionとWeb<!-- --><br/>に興味があります<!-- --></p></div><div class="tableOfContents-module--tocRoot--t6LR+"><h3 style="text-align:center">Contents</h3><ul class="tableOfContents-module--tocItem--MZysC"><li><a href="#dataparallel-と-distributeddataparallel">DataParallel と DistributedDataParallel</a></li><li><a href="#distributeddataparallel-の実行方法">DistributedDataParallel の実行方法</a></li><li><a href="#新しい実行方法-torchrun">新しい実行方法 torchrun</a></li><li><a href="#参考">参考</a></li></ul></div></div><div class="main" style="margin-bottom:2em"><div class="post-module--postMain--oWbD+"><h1 class="post-module--postTitle--eWkbD">PyTorchのMultiGPUの概要 【DataParallel, DistributedDataParallel, torchrun】</h1><ul class="post-module--postMetas--mQGzs"><li class="date">2022.04.18</li><li class="update">Updated: <!-- -->2022.07.27<!-- --></li><li class="post-module--postMeta--t+-D+"><a class="post-module--link--T97u1" href="/category/py-torch"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="tag" class="svg-inline--fa fa-tag fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" width="32" height="32"><path fill="currentColor" d="M0 252.118V48C0 21.49 21.49 0 48 0h204.118a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882 0L14.059 286.059A48 48 0 0 1 0 252.118zM112 64c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"></path></svg>PyTorch<!-- --></a></li><li class="post-module--postMeta--t+-D+"><a class="post-module--link--T97u1" href="/tag/py-torch/"><span>#<!-- -->PyTorch<!-- --> <!-- --></span></a><a class="post-module--link--T97u1" href="/tag/python/"><span>#<!-- -->Python<!-- --> <!-- --></span></a></li></ul><div class="post-module--markdown--o91q7"><p>機械学習ライブラリの PyTorch には、複数のマシン・GPU で
学習を行う方法がいくつか用意されている。<!-- --><br/>
<!-- -->この記事を書いている現在、PyTorch の stable version は<!-- --><code class="language-text">1.11.0</code>であるが、
実行方法が、直近の version<!-- --><code class="language-text">1.9.0</code>と<!-- --><code class="language-text">1.10.0</code>で変更・追加があったのでまとめる。<!-- --></p><h2 id="dataparallel-と-distributeddataparallel">DataParallel と DistributedDataParallel</h2><p>PyTorch で複数の GPU を用いた Training の実装方法は 2 つある。</p><ol><li><code class="language-text">torch.nn.DataParallel</code></li><li><code class="language-text">torch.nn.DistributedDataParallel</code></li></ol><p>この２つの違いは、複数の GPU に割り当てられるCPUコアが
全体で1つか各GPUに複数かである。</p><p><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:800px">
      <!-- --><a class="gatsby-resp-image-link" href="/static/f267346af6b6d553c5249a7e92c166b6/f43b1/torch_dist.jpg" style="display:block" target="_blank" rel="noopener">
    <!-- --><span class="gatsby-resp-image-background-image" style="padding-bottom:55.99999999999999%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAEDBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHtTaQB/8QAGRAAAgMBAAAAAAAAAAAAAAAAAAECEBEx/9oACAEBAAEFAp6S1C4Ov//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABcQAAMBAAAAAAAAAAAAAAAAAAABICH/2gAIAQEABj8CRk//xAAaEAADAAMBAAAAAAAAAAAAAAAAAREhMUFR/9oACAEBAAE/IWRwuwzIbwaL4QRNmj//2gAMAwEAAgADAAAAEEPv/8QAFREBAQAAAAAAAAAAAAAAAAAAEBH/2gAIAQMBAT8Qh//EABcRAAMBAAAAAAAAAAAAAAAAAAEQIRH/2gAIAQIBAT8Qw2r/xAAZEAEBAQADAAAAAAAAAAAAAAABEQAhMVH/2gAIAQEAAT8QrG0qL17xmHGLOVreu81cRRTIthfZhFN4N//Z&#x27;);background-size:cover;display:block"></span>
  <!-- --><img class="gatsby-resp-image-image" alt="nvidia-diff-parallel" title="nvidia-diff-parallel" src="/static/f267346af6b6d553c5249a7e92c166b6/4b190/torch_dist.jpg" srcSet="/static/f267346af6b6d553c5249a7e92c166b6/e07e9/torch_dist.jpg 200w,/static/f267346af6b6d553c5249a7e92c166b6/066f9/torch_dist.jpg 400w,/static/f267346af6b6d553c5249a7e92c166b6/4b190/torch_dist.jpg 800w,/static/f267346af6b6d553c5249a7e92c166b6/e5166/torch_dist.jpg 1200w,/static/f267346af6b6d553c5249a7e92c166b6/f43b1/torch_dist.jpg 1426w" sizes="(max-width: 800px) 100vw, 800px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" loading="lazy" decoding="async"/>
  <!-- --></a>
    <!-- --></span></p><p>上記の図<!-- --><sup id="fnref-1"><a href="#fn-1" class="footnote-ref">1</a></sup>のように、Python の GIL の都合もあり、
<!-- --><code class="language-text">DistributedDataParallel</code>を使ったほうが各 GPU に個別の CPU コアを割り当てられるので、
リソースを存分に使うことができる。
また、複数のマシン(Multi-node)で実行できるのも強みである。
実際、公式ドキュメント<!-- --><sup id="fnref-2"><a href="#fn-2" class="footnote-ref">2</a></sup>でも<!-- --><code class="language-text">DistributedDataParallel</code>が勧められている。<!-- --></p><p>ここまでくると、<!-- --><code class="language-text">DataParallel</code>のメリットが感じられないが、実装の違いを
見ると利点が見えてくる。<!-- --></p><p>まず、<!-- --><code class="language-text">DataParallel</code>の実装は以下である。<!-- --></p><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> torch

model <!-- --><span class="token operator">=</span> hoge<!-- --><span class="token punctuation">(</span><span class="token punctuation">)</span>
<!-- --><span class="token operator">+</span> model <!-- --><span class="token operator">=</span> torch<!-- --><span class="token punctuation">.</span>nn<!-- --><span class="token punctuation">.</span>DataParallel<!-- --><span class="token punctuation">(</span>model<!-- --><span class="token punctuation">,</span> device_ids<!-- --><span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre></div><p>上記のように既存のモデル(<!-- --><code class="language-text">torch.nn.Model</code>)に対して、<!-- --><code class="language-text">torch.nn.DataParallel</code>をラップするだけで
実装でき、既存のコードを 1 行変更するだけで実装することができる。<!-- --></p><p>次に、<!-- --><code class="language-text">DistributedDataParallel</code>の実装例を確認する。<!-- --></p><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> os
<!-- --><span class="token keyword">import</span> torch
<!-- --><span class="token keyword">import</span> torch<!-- --><span class="token punctuation">.</span>distributed <!-- --><span class="token keyword">as</span> dist
<!-- --><span class="token keyword">from</span> torch<!-- --><span class="token punctuation">.</span>nn<!-- --><span class="token punctuation">.</span>parallel <!-- --><span class="token keyword">import</span> DistributedDataParallel <!-- --><span class="token keyword">as</span> DDP
<!-- --><span class="token keyword">from</span> torch<!-- --><span class="token punctuation">.</span>utils<!-- --><span class="token punctuation">.</span>data<!-- --><span class="token punctuation">.</span>distributed <!-- --><span class="token keyword">import</span> DistributedSampler

<!-- --><span class="token comment"># どのGPUプロセス番号かがLocal Rank</span>
<!-- --><span class="token comment"># GPU ID = 1の時、local_rank=1</span>
local_rank <!-- --><span class="token operator">=</span> os<!-- --><span class="token punctuation">.</span>getenv<!-- --><span class="token punctuation">(</span><span class="token string">&#x27;LOCAL_RANK&#x27;</span><span class="token punctuation">,</span> <!-- --><span class="token number">0</span><span class="token punctuation">)</span>

<!-- --><span class="token comment"># 通信方法の規定とプロセスグループの初期化</span>
dist<!-- --><span class="token punctuation">.</span>init_process_group<!-- --><span class="token punctuation">(</span>backend<!-- --><span class="token operator">=</span><span class="token string">&#x27;nccl&#x27;</span><span class="token punctuation">,</span> init_method<!-- --><span class="token operator">=</span><span class="token string">&#x27;env://&#x27;</span><span class="token punctuation">)</span>

dataset <!-- --><span class="token operator">=</span> Dataset<!-- --><span class="token punctuation">(</span>hoge<!-- --><span class="token punctuation">)</span>

<!-- --><span class="token comment"># DistributedSamplerを使う</span>
sampler <!-- --><span class="token operator">=</span> DistributedSampler<!-- --><span class="token punctuation">(</span>dataset<!-- --><span class="token punctuation">,</span> rank<!-- --><span class="token operator">=</span>local_rank<!-- --><span class="token punctuation">)</span>
dataloaders <!-- --><span class="token operator">=</span> torch<!-- --><span class="token punctuation">.</span>utils<!-- --><span class="token punctuation">.</span>data<!-- --><span class="token punctuation">.</span>DataLoader<!-- --><span class="token punctuation">(</span>dataset<!-- --><span class="token punctuation">,</span>
                                          batch_size<!-- --><span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
                                          sampler<!-- --><span class="token operator">=</span>Distributed<!-- --><span class="token punctuation">)</span>

<!-- --><span class="token comment"># DistributedDataParallelでラップ</span>
model <!-- --><span class="token operator">=</span> Model<!-- --><span class="token punctuation">(</span>fuga<!-- --><span class="token punctuation">)</span>
model <!-- --><span class="token operator">=</span> DDP<!-- --><span class="token punctuation">(</span>model<!-- --><span class="token punctuation">)</span>

<!-- --><span class="token comment"># ...</span>

<!-- --><span class="token comment"># Training終了</span>
dist<!-- --><span class="token punctuation">.</span>destroy_process_group<!-- --><span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre></div><p><code class="language-text">DistributedDataParallel</code>では、シングル・マルチマシンの場合も同じ書き方ができるように
設計されているため、新たに実装する部分が多い。
マルチプロセスになった分、自分が今どのプロセスにいるのかを意識しながら実装を進める必要がある。<!-- --></p><p>上記の通り、<!-- --><code class="language-text">DataParallel</code>は 1 行で既存のコードを変更することができるが、
<!-- --><code class="language-text">DistributedDataParallel</code>は多少の追加実装が必要になる。
手軽に複数 GPU での Training を試したい場合は、<!-- --><code class="language-text">DataParallel</code>を用いるとよい。<!-- --></p><p>次章では新たに追加された<!-- --><code class="language-text">torchrun</code>について議論するため、以下からは<!-- --><code class="language-text">DistributedDataParallel</code>
を用いた場合について考える。<!-- --></p><h2 id="distributeddataparallel-の実行方法">DistributedDataParallel の実行方法</h2><p>DistributedDataParallel の実行方法は、大きく分けて以下の２つある。</p><ol><li>特定の関数について GPU 並列化を行う方法(<!-- --><code class="language-text">mp.spawn</code>)<!-- --></li><li>スクリプトごと GPU 並列化する方法(<!-- --><code class="language-text">torchrun</code>, <!-- --><code class="language-text">torch.distributed.run</code>, <!-- --><code class="language-text">torch.distributed.launch</code>)<!-- --></li></ol><h3 id="1-関数について並列化">1. 関数について並列化</h3><p>1 の関数ごとに並列化する方法は、コード内で Training を行う関数を書いて、使用する GPU の数や
通信方法もコード内で設定して実行することができる。
つまり、シングル GPU であっても、複数 GPU のコードであっても<!-- --><code class="language-text">python train.py</code>と、
同じコマンドの実行で学習が行える。<!-- --><br/>
<!-- -->実装例は PyTorch 公式の ImageNet 学習の実装に書かれている。<!-- --></p><p><a href="https://github.com/pytorch/examples/tree/main/imagenet">https://github.com/pytorch/examples/tree/main/imagenet</a></p><p>2 の方法と大きく異なる部分が、以下の部分である。</p><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> torch<!-- --><span class="token punctuation">.</span>multiprocessing <!-- --><span class="token keyword">as</span> mp

<!-- --><span class="token keyword">def</span> <!-- --><span class="token function">train</span><span class="token punctuation">(</span>rank<!-- --><span class="token punctuation">,</span> hoge<!-- --><span class="token punctuation">)</span><span class="token punctuation">:</span>
    dist<!-- --><span class="token punctuation">.</span>init_process_group<!-- --><span class="token punctuation">(</span>backend<!-- --><span class="token operator">=</span><span class="token string">&#x27;nccl&#x27;</span><span class="token punctuation">,</span> init_method<!-- --><span class="token operator">=</span><span class="token string">&#x27;env://&#x27;</span><span class="token punctuation">)</span>

<!-- --><span class="token keyword">def</span> <!-- --><span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    mp<!-- --><span class="token punctuation">.</span>spawn<!-- --><span class="token punctuation">(</span>train<!-- --><span class="token punctuation">,</span> nprocs<!-- --><span class="token operator">=</span>ngpus_per_node<!-- --><span class="token punctuation">,</span> args<!-- --><span class="token operator">=</span><span class="token punctuation">(</span>hoge<!-- --><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre></div><p>上記の通り、コード自体は Python 標準モジュールの multiprocessing と変わりない。<!-- --><br/>
<!-- -->しかし、標準モジュールは CUDA Initialized を複数行ってしまい、エラーが発生するため、
multiprocessing モジュールをラップした、<!-- --><code class="language-text">torch.multiprocessing</code>を使用する。<!-- --></p><h3 id="2-スクリプトごと並列化">2. スクリプトごと並列化</h3><p>2 の方法については PyTorch のバージョンによって実行方法が異なっており、
version 1.9.0 以前は、<!-- --><br/>
<!-- --><code class="language-text">python -m torch.distributed.launch --nproc_per_node=4 --nnodes=1 --node_rank 0 train.py</code><br/>
<!-- -->で実行されていたが、version 1.9.0 以降は TorchElastic が追加された影響で<!-- --><br/>
<!-- --><code class="language-text">python -m torch.distributed.run --nproc_per_node=4 --nnodes=1 --node_rank 0 train.py</code><br/>
<!-- -->でも実行できる。<!-- --><br/>
<!-- -->また、<!-- --><code class="language-text">torch.distributed.launch</code>の super set として、<!-- --><code class="language-text">torchrun</code>が Version 1.10.0 から提供されている。<!-- --></p><p>ここでは従来の方法である、<!-- --><code class="language-text">torch.distributed.launch</code>と<!-- --><code class="language-text">torch.distributed.run</code>について述べる。<!-- --></p><p><code class="language-text">torch.distributed.launch</code>と<!-- --><code class="language-text">torch.distributed.run</code>の場合、
実行スクリプトの<!-- --><code class="language-text">train.py</code>にはコマンドライン引数として
<!-- --><code class="language-text">--local_rank</code>を受け取れるように実装する必要がある。下に例を示す。<!-- --></p><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> argparse
parser <!-- --><span class="token operator">=</span> argparse<!-- --><span class="token punctuation">.</span>ArgumentParser<!-- --><span class="token punctuation">(</span><span class="token punctuation">)</span>
parser<!-- --><span class="token punctuation">.</span>add_argument<!-- --><span class="token punctuation">(</span><span class="token string">&quot;--local_rank&quot;</span><span class="token punctuation">,</span> <!-- --><span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">)</span>
args <!-- --><span class="token operator">=</span> parser<!-- --><span class="token punctuation">.</span>parse_args<!-- --><span class="token punctuation">(</span><span class="token punctuation">)</span>

local_rank <!-- --><span class="token operator">=</span> args<!-- --><span class="token punctuation">.</span>local_rank<!-- --></code></pre></div><p>これ以外の実装は 1 の関数ごとに multiprocessing する場合と変わらない。</p><h3 id="1-と-2-の実行方法の違いについて">1 と 2 の実行方法の違いについて</h3><p>1 の関数を multiprocessing する方法と、スクリプト自体を multiprocessing する方法は、
<!-- --><a href="%5E3">こちらの公式フォーラム</a>
<!-- --><sup id="fnref-3"><a href="#fn-3" class="footnote-ref">3</a></sup>でも言及されているように、
<!-- --><code class="language-text">multiprocessing(1) vs subprocess(2)</code>の違いといえる。<!-- --></p><p>Github の Issue<!-- --><sup id="fnref-4"><a href="#fn-4" class="footnote-ref">4</a></sup> <!-- --><sup id="fnref-5"><a href="#fn-5" class="footnote-ref">5</a></sup>では、1 の方法が GPU への転送速度の関係で遅いという報告もある。
長い時間の学習では無視できるようだが、参考としておきたい。<!-- --></p><h2 id="新しい実行方法-torchrun">新しい実行方法 <!-- --><code class="language-text">torchrun</code></h2><p>PyTorch の Version 1.10.0 から、<!-- --><code class="language-text">torch.distributed.launch</code>の super set として、<!-- --><code class="language-text">torchrun</code>が登場している。<!-- --></p><p>公式ドキュメント<!-- --><sup id="fnref-6"><a href="#fn-6" class="footnote-ref">6</a></sup>にわかりやすい移行手順があるので、一読をお勧めする。<!-- --></p><p>具体的には、実行コマンドが以下のように変更され、</p><div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token comment"># use_envはLOCAL RANKをargparseではなく、</span>
<!-- --><span class="token comment"># 環境変数から受け取るオプション</span>
python -m torch.distributed.launch --use_env train_script.py

torchrun train_script.py<!-- --></code></pre></div><p>argparse で受け取っていた local rank を環境変数から受け取るようになる。</p><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token comment"># torch.distributed.launch</span>
<!-- --><span class="token keyword">import</span> argparse
parser <!-- --><span class="token operator">=</span> argparse<!-- --><span class="token punctuation">.</span>ArgumentParser<!-- --><span class="token punctuation">(</span><span class="token punctuation">)</span>
parser<!-- --><span class="token punctuation">.</span>add_argument<!-- --><span class="token punctuation">(</span><span class="token string">&quot;--local_rank&quot;</span><span class="token punctuation">,</span> <!-- --><span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">)</span>
args <!-- --><span class="token operator">=</span> parser<!-- --><span class="token punctuation">.</span>parse_args<!-- --><span class="token punctuation">(</span><span class="token punctuation">)</span>

local_rank <!-- --><span class="token operator">=</span> args<!-- --><span class="token punctuation">.</span>local_rank

<!-- --><span class="token comment"># torchrun</span>
<!-- --><span class="token keyword">import</span> os
local_rank <!-- --><span class="token operator">=</span> <!-- --><span class="token builtin">int</span><span class="token punctuation">(</span>os<!-- --><span class="token punctuation">.</span>environ<!-- --><span class="token punctuation">[</span><span class="token string">&quot;LOCAL_RANK&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre></div><p>ほとんど使用感は変わりないが、わざわざ argparse で引数の受取先を作らなくてよくなったのは、
コマンドライン引数の名前空間を汚されなくて済むので利点がある。<!-- --><br/>
<!-- -->例えば、Facebook 謹製の設定管理ライブラリの
<!-- --><a href="https://hydra.cc/">Hydra</a> <!-- --><sup id="fnref-7"><a href="#fn-7" class="footnote-ref">7</a></sup>を使っている場合、argparse と併用ができないので、
torchrun で環境変数を経由するメリットがある。<!-- --><br/>
<!-- -->(ただし、ここ<!-- --><sup id="fnref-8"><a href="#fn-8" class="footnote-ref">8</a></sup> <!-- --><sup id="fnref-9"><a href="#fn-9" class="footnote-ref">9</a></sup>で議論されているように、output 周りが conflict する問題があるので、
今後の動向に注目するべきである。)<!-- --></p><p>ここ<!-- --><sup id="fnref-10"><a href="#fn-10" class="footnote-ref">10</a></sup>で、書かれているように<!-- --><code class="language-text">torch.distributed.launch</code>
は将来的に deprecated したいようなので、今後は torchrun で実装していくべきだろう。<!-- --></p><h2 id="参考">参考</h2><div class="footnotes"><hr/><ol><li id="fn-1"><a href="https://qiita.com/sugulu_Ogawa_ISID/items/62f5f7adee083d96a587#4-multi-gpu%E3%81%AE%E8%A8%AD%E5%AE%9A">https://qiita.com/sugulu_Ogawa_ISID/items/62f5f7adee083d96a587#4-multi-gpu%E3%81%AE%E8%A8%AD%E5%AE%9A</a><a href="#fnref-1" class="footnote-backref">↩</a></li><li id="fn-2"><a href="https://pytorch.org/docs/1.11/notes/cuda.html#use-nn-parallel-distributeddataparallel-instead-of-multiprocessing-or-nn-dataparallel">https://pytorch.org/docs/1.11/notes/cuda.html#use-nn-parallel-distributeddataparallel-instead-of-multiprocessing-or-nn-dataparallel</a><a href="#fnref-2" class="footnote-backref">↩</a></li><li id="fn-3"><a href="https://discuss.pytorch.org/t/torch-distributed-launch-vs-torch-multiprocessing-spawn/95738">https://discuss.pytorch.org/t/torch-distributed-launch-vs-torch-multiprocessing-spawn/95738</a><a href="#fnref-3" class="footnote-backref">↩</a></li><li id="fn-4"><a href="https://github.com/pytorch/pytorch/issues/47587">https://github.com/pytorch/pytorch/issues/47587</a><a href="#fnref-4" class="footnote-backref">↩</a></li><li id="fn-5"><a href="https://github.com/NVIDIA/apex/issues/549">https://github.com/NVIDIA/apex/issues/549</a><a href="#fnref-5" class="footnote-backref">↩</a></li><li id="fn-6"><a href="https://pytorch.org/docs/1.11/elastic/run.html">https://pytorch.org/docs/1.11/elastic/run.html</a><a href="#fnref-6" class="footnote-backref">↩</a></li><li id="fn-7"><a href="https://hydra.cc/">https://hydra.cc/</a><a href="#fnref-7" class="footnote-backref">↩</a></li><li id="fn-8"><a href="https://github.com/facebookresearch/hydra/pull/2119">https://github.com/facebookresearch/hydra/pull/2119</a><a href="#fnref-8" class="footnote-backref">↩</a></li><li id="fn-9"><a href="https://github.com/facebookresearch/hydra/issues/2038">https://github.com/facebookresearch/hydra/issues/2038</a><a href="#fnref-9" class="footnote-backref">↩</a></li><li id="fn-10"><a href="https://pytorch.org/docs/1.11/distributed.html#launch-utility">https://pytorch.org/docs/1.11/distributed.html#launch-utility</a><a href="#fnref-10" class="footnote-backref">↩</a></li></ol></div></div></div></div></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/posts/2022-04-18-torchrun/";window.___webpackCompilationHash="01c4a66796f357ca3df4";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-75483171cdc06cd91f13.js"],"app":["/app-fb1898ca3cc5ab8fa7a6.js"],"component---src-pages-404-js":["/component---src-pages-404-js-fbc24ed8eeb4b46bf79a.js"],"component---src-pages-about-js":["/component---src-pages-about-js-f79d3023c77c234d000b.js"],"component---src-pages-categories-js":["/component---src-pages-categories-js-51092f77a81abbbeb936.js"],"component---src-pages-tags-js":["/component---src-pages-tags-js-e9059bb119741c23295e.js"],"component---src-templates-categories-js":["/component---src-templates-categories-js-3491f11a3ed741017d60.js"],"component---src-templates-index-js":["/component---src-templates-index-js-db834d6b3a9fb6e27f21.js"],"component---src-templates-post-js":["/component---src-templates-post-js-f819aabdc660afd8ccb6.js"],"component---src-templates-tags-js":["/component---src-templates-tags-js-87b39c57f4a295b4b7dc.js"]};/*]]>*/</script><script src="/polyfill-75483171cdc06cd91f13.js" nomodule=""></script><script src="/component---src-templates-post-js-f819aabdc660afd8ccb6.js" async=""></script><script src="/commons-57e03994e03942ac0f58.js" async=""></script><script src="/app-fb1898ca3cc5ab8fa7a6.js" async=""></script><script src="/framework-e9e354935324f36f552a.js" async=""></script><script src="/webpack-runtime-383a21dce55454d79a33.js" async=""></script></body></html>