---
title: TorchVisionã®transforms.v2ã‚’è§¦ã£ã¦ã¿ãŸ
tags: [PyTorch]
category: PyTorch
date: 2023-10-11
update: 2023-10-11
# for Zenn
type: tech
emoji: ğŸ˜–
topics: [None]
published: true
---

å…ˆæ—¥ï¼ŒPyTorchã®ç”»åƒæ“ä½œç³»ã®å‡¦ç†ãŒã¾ã¨ã¾ã£ãŸãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ŒTorchVisionã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³0.16.0ãŒå…¬é–‹ã•ã‚Œã¾ã—ãŸï¼
ã“ã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã§ï¼Œãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã§ã‚ˆãç”¨ã„ã‚‰ã‚Œã‚‹`torchvision.transforms`ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³v2ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒåŠ ç­†ã•ã‚Œã¾ã—ãŸï¼
`torchvision.transforms.v2`è‡ªä½“ã¯ãƒ™ãƒ¼ã‚¿ç‰ˆã¨ã—ã¦0.15.0ã‹ã‚‰å­˜åœ¨ã—ã¦ã„ãŸã‚‚ã®ã®ï¼Œä»Šå›ã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒå……å®Ÿã—ï¼Œrecommendã«ãªã£ãŸã“ã¨ã‹ã‚‰ï¼Œ
å®Ÿéš›ã«ä»¥å‰ã®æ–¹æ³•ã¨ã©ã®ã‚ˆã†ã«ç•°ãªã‚‹ã®ã‹è¦‹ã¦ã„ããŸã„ã¨æ€ã„ã¾ã™ï¼
ãªãŠï¼Œv2ã¯ã¾ã ãƒ™ãƒ¼ã‚¿ç‰ˆã§ã™ï¼0.17.0ã§å®‰å®šç‰ˆã¨ãªã‚‹ã‚ˆã†ã§ã™ï¼

- ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆ

<https://github.com/pytorch/vision/releases/tag/v0.16.0>

- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

<https://pytorch.org/vision/stable/transforms.html#v2-api-reference-recommended>

ä»Šå¾Œã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã¯v2ã®ã¿ã«è¡Œã‚ã‚Œã‚‹ã‚ˆã†ãªã®ã§ï¼Œã“ã®æ©Ÿä¼šã«ç§»è¡Œã—ã¦ãŠããŸã„ã¨ã“ã‚ã§ã™ï¼

## ä¸»ãªå¤‰æ›´ç‚¹

- transformsã®å…¥åŠ›ã¨ã—ã¦ç‰©ä½“æ¤œå‡ºã®BBoxã‚„ï¼Œã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¯ï¼Œå‹•ç”»ã‚’æ‰±ãˆã‚‹ã‚ˆã†ã«ãªã£ãŸç‚¹
- CutMixã‚„MixUpã¨ã„ã£ãŸãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæ‰‹æ³•ã«å¯¾å¿œã—ãŸç‚¹
- é«˜é€ŸåŒ–
- ä»»æ„ã®å…¥åŠ›(dict, lists, tuplesãªã©)ã‚’å—ã‘ä»˜ã‘ã‚‹
- Resizeãªã©ãŒtorch.uint8å‹ã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚Œã‚‹

ä¸Šè¨˜ã®å¤‰æ›´ç‚¹ã‚’ã‚‚ã¨ã«ï¼Œv2ã§ã¯ä»¥ä¸‹ã®æ–¹æ³•ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã¾ã™ï¼

- PIL.Imageå‹ã®ä»£ã‚ã‚Šã«ï¼ŒTensorå‹ã‚’å…¥åŠ›ã¨ã™ã‚‹
- Resizeãªã©ã‚’è¡Œã†å ´åˆã¯ï¼Œå…¥åŠ›ã‚’torch.uint8([0~255])ã«ã™ã‚‹
- Resizeã¯ãƒã‚¤ãƒªãƒ‹ã‚¢ã‹ãƒã‚¤ã‚­ãƒ¥ãƒ¼ãƒ“ãƒƒã‚¯ã§è¡Œã†

## ç§»è¡Œæ–¹æ³•

ç§»è¡Œæ–¹æ³•ã¯ç°¡å˜ã§ã™ï¼ä»Šã¾ã§`import torchvision.transforms`ã¨ã—ã¦ã„ãŸã¨ã“ã‚ã‚’ï¼Œ`import torchvision.transforms.v2`ã¨ã™ã‚‹ã ã‘ã§ã™ï¼

```python
# V1
from torchvision import transforms

# V2(transformsã®ã¾ã¾v2ã‚’å‘¼ã³å‡ºã™å ´åˆ)
from torchvision.transforms import v2 as transforms
```

## å®Ÿé¨“1: å¤‰æ›é€Ÿåº¦ã®è¨ˆæ¸¬

å‰è¿°ã—ãŸé€šã‚Šï¼ŒV2ã§ã¯transformsã®é«˜é€ŸåŒ–ã‚„uint8å‹ã¸ã®å¯¾å¿œãŒå¤‰æ›´ç‚¹ã¨ã—ã¦æŒ™ã’ã‚‰ã‚Œã¦ã„ã¾ã™ï¼
ãã“ã§ï¼Œv1, v2ã§é€Ÿåº¦ã®è¨ˆæ¸¬ã‚’è¡Œã£ã¦ã¿ãŸã„ã¨æ€ã„ã¾ã™ï¼

v1, v2ã«ã¤ã„ã¦ï¼ŒPIL.Imageã¨Tensorå‹ã§å…¥åŠ›ã—ãŸå ´åˆã§ãã‚Œãã‚Œæ¯”è¼ƒã—ã¦ã¿ã¾ã™ï¼

å…¥åŠ›ç”»åƒã¨ã—ã¦ä»¥ä¸‹ã‚’ç”¨æ„ã—ã¾ã—ãŸï¼
Resizeã®åŠ¹æœã‚’è¦‹ãŸã„ã®ã§ï¼Œå¤§ãã‚ã®ã‚µã‚¤ã‚ºã®ç”»åƒã‚’ç”¨æ„ã—ã¾ã—ãŸï¼

![otter](./images/torchvisionv2_2.png)

> å¼•ç”¨: <https://publicdomainq.net/otter-animal-0014492/>

```bash
identify image.jpg
image.jpg JPEG 3872x2592 3872x2592+0+0 8-bit sRGB 1.93051MiB 0.000u 0:00.001
```

æ¸¬å®šã—ãŸã‚³ãƒ¼ãƒ‰ã¯ä»¥ä¸‹ã§ã™ï¼

```python
import time

import torch
import torchvision
import torchvision.transforms as v1
import torchvision.transforms.v2 as v2
from PIL import Image


def get_v1_transforms_tensor():
    return v1.Compose(
        [
            v1.RandomHorizontalFlip(p=0.5),
            v1.RandomVerticalFlip(p=0.5),
            v1.RandomResizedCrop((224, 224), (0.01, 2.0), antialias=False),
            v1.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
        ]
    )


def get_v2_transforms_tensor():
    return v2.Compose(
        [
            v2.RandomHorizontalFlip(p=0.5),
            v2.RandomVerticalFlip(p=0.5),
            v2.RandomResizedCrop((224, 224), (0.01, 2.0), antialias=False),
            v2.ToDtype(torch.float32, scale=True),
            v2.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
        ]
    )


def get_v1_transforms_pil():
    return v1.Compose(
        [
            v1.ToTensor(),
            v1.RandomHorizontalFlip(p=0.5),
            v1.RandomVerticalFlip(p=0.5),
            v1.RandomResizedCrop((224, 224), (0.01, 2.0), antialias=False),
            v1.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
        ]
    )


def get_v2_transforms_pil():
    return v2.Compose(
        [
            v2.ToImage(),
            v2.RandomHorizontalFlip(p=0.5),
            v2.RandomVerticalFlip(p=0.5),
            v2.RandomResizedCrop((224, 224), (0.01, 2.0), antialias=False),
            v2.ToDtype(torch.float32, scale=True),
            v2.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
        ]
    )


def main():
    num_iter = 200

    transforms = get_v1_transforms_tensor()
    elapsed_times = []
    for _ in range(num_iter):
        img = torchvision.io.read_image("./image.jpg")

        t = time.time()
        img = img / 255
        transforms(img)
        elapsed_times.append(time.time() - t)
    elapsed_times = elapsed_times[len(elapsed_times) // 2 :]
    print("V1 Elapsed Time(Input Tensor): ", sum(elapsed_times) / len(elapsed_times) * 1000, "ms")

    transforms = get_v2_transforms_tensor()
    elapsed_times = []
    for _ in range(num_iter):
        img = torchvision.io.read_image("./image.jpg")

        t = time.time()
        transforms(img)
        elapsed_times.append(time.time() - t)
    elapsed_times = elapsed_times[len(elapsed_times) // 2 :]
    print("V2 Elapsed Time(Input Tensor): ", sum(elapsed_times) / len(elapsed_times) * 1000, "ms")

    transforms = get_v1_transforms_pil()
    elapsed_times = []
    for _ in range(num_iter):
        img = Image.open("./image.jpg").convert("RGB")
        t = time.time()
        transforms(img)
        elapsed_times.append(time.time() - t)
    elapsed_times = elapsed_times[len(elapsed_times) // 2 :]
    print("V1 Elapsed Time(Input PIL): ", sum(elapsed_times) / len(elapsed_times) * 1000, "ms")

    transforms = get_v2_transforms_pil()
    elapsed_times = []
    for _ in range(num_iter):
        img = Image.open("./image.jpg").convert("RGB")
        t = time.time()
        transforms(img)
        elapsed_times.append(time.time() - t)
    elapsed_times = elapsed_times[len(elapsed_times) // 2 :]
    print("V2 Elapsed Time(Input PIL): ", sum(elapsed_times) / len(elapsed_times) * 1000, "ms")


if __name__ == "__main__":
    main()
```

å®Ÿè¡Œçµæœã¯ä»¥ä¸‹ã¨ãªã‚Šã¾ã—ãŸï¼

```bash
python exp.py
V1 Elapsed Time(Input Tensor):  42.47044086456299 ms
V2 Elapsed Time(Input Tensor):  4.662487506866455 ms
V1 Elapsed Time(Input PIL):  63.41712474822998 ms
V2 Elapsed Time(Input PIL):  13.053297996520996 ms
```

ã¾ã¨ã‚ã‚‹ã¨ä»¥ä¸‹ã§ã™ï¼

| version | Input  | elapsed time |
|---------|--------|-------------:|
| v1      | Tensor |      42.4704 |
| v2      | Tensor |       4.6625 |
| v1      | PIL    |      63.4171 |
| v2      | PIL    |      13.0533 |

ä»Šå›ã®å ´åˆã¯ï¼ŒTensorã‚’å…¥åŠ›ã—ãŸå ´åˆã¯9.1å€ï¼ŒPILã‚’å…¥åŠ›ã—ãŸå ´åˆã¯4.9å€ã®é«˜é€ŸåŒ–ã¨ãªã‚Šã¾ã—ãŸï¼
ã ã„ã¶æ—©ã„ã§ã™ã­ã€œï¼

## å®Ÿé¨“2: Boxã‚’å…¥åŠ›ã—ã¦ã¿ã‚‹

ä»Šã¾ã§ã®transformsã¯ï¼Œç”»åƒã—ã‹å…¥åŠ›ã§ãã¾ã›ã‚“ã§ã—ãŸãŒï¼Œä»Šå›ã‹ã‚‰BBoxã‚„maskã‚’å…¥åŠ›ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã¿ãŸã„ã§ã™ï¼
ã¨ã„ã†ã‚ã‘ã§ï¼Œä»Šå›ã¯ç°¡å˜ã«ç”¨æ„ã§ãã‚‹BBoxã‚’ä½¿ã£ã¦å®Ÿé¨“ã—ã¦ã¿ã‚ˆã†ã¨æ€ã„ã¾ã™ï¼

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯å…¬å¼ã®Tutorialã‹ã‚‰æ‹å€Ÿã—ã¾ã—ãŸï¼

https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_getting_started.html

```python
import matplotlib.pyplot as plt
import torch
from torchvision import tv_tensors
from torchvision.io import read_image
from torchvision.transforms import v2
from torchvision.transforms.v2 import functional as F
from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks


def plot(imgs, row_title=None, **imshow_kwargs):
    if not isinstance(imgs[0], list):
        # Make a 2d grid even if there's just 1 row
        imgs = [imgs]

    num_rows = len(imgs)
    num_cols = len(imgs[0])
    _, axs = plt.subplots(nrows=num_rows, ncols=num_cols, squeeze=False)
    for row_idx, row in enumerate(imgs):
        for col_idx, img in enumerate(row):
            boxes = None
            masks = None
            if isinstance(img, tuple):
                img, target = img
                if isinstance(target, dict):
                    boxes = target.get("boxes")
                    masks = target.get("masks")
                elif isinstance(target, tv_tensors.BoundingBoxes):
                    boxes = target
                else:
                    raise ValueError(f"Unexpected target type: {type(target)}")
            img = F.to_image(img)
            if img.dtype.is_floating_point and img.min() < 0:
                # Poor man's re-normalization for the colors to be OK-ish. This
                # is useful for images coming out of Normalize()
                img -= img.min()
                img /= img.max()

            img = F.to_dtype(img, torch.uint8, scale=True)
            if boxes is not None:
                img = draw_bounding_boxes(img, boxes, colors="yellow", width=3)
            if masks is not None:
                img = draw_segmentation_masks(
                    img, masks.to(torch.bool), colors=["green"] * masks.shape[0], alpha=0.65
                )

            ax = axs[row_idx, col_idx]
            ax.imshow(img.permute(1, 2, 0).numpy(), **imshow_kwargs)
            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])

    if row_title is not None:
        for row_idx in range(num_rows):
            axs[row_idx, 0].set(ylabel=row_title[row_idx])

    plt.tight_layout()


def main():
    img = read_image("./image.jpg")

    boxes = tv_tensors.BoundingBoxes(
        [[500, 500, 2540, 2540]],
        format="XYXY",
        canvas_size=img.shape[-2:],
    )

    transforms = v2.Compose(
        [
            v2.RandomResizedCrop(size=(1024, 1024), antialias=True),
            v2.RandomPhotometricDistort(p=1),
            v2.RandomHorizontalFlip(p=1),
        ]
    )
    out_img, out_boxes = transforms(img, boxes)
    print(type(boxes), type(out_boxes))

    plot([(img, boxes), (out_img, out_boxes)])
    plt.show()


if __name__ == "__main__":
    main()
```

çµæœã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼

![box](./images/torchvisionv2_2.png)

ä¸Šè¨˜ã®ã‚³ãƒ¼ãƒ‰ä¾‹ã§é‡è¦ãªéƒ¨åˆ†ã¯ã“ã“ã§ã™ï¼

```python
boxes = tv_tensors.BoundingBoxes(
            [[500, 500, 2540, 2540]],
            format="XYXY",
            canvas_size=img.shape[-2:],
        )
```

v2ã§ã¯BBoxã¯`tv_tensors.BoundingBoxes`ã«ï¼Œ
Maskã¯`tv_tensors.Mask`ã«å…¥ã‚Œã¦å…¥åŠ›ã™ã‚‹ã“ã¨ã§ï¼ŒBoxãƒ»Maskã¸ã‚‚ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãŒã§ãã‚‹ã‚ˆã†ã§ã™ï¼

## ã¾ã¨ã‚

ä»¥ä¸Šç°¡å˜ã«ã§ã™ãŒï¼Œtorchvision.transformsã®v2ã®ç´¹ä»‹ã§ã—ãŸï¼
å®Ÿé¨“1ã§ç¤ºã—ãŸã‚ˆã†ã«ï¼ŒResizeã‚’uint8ã§å‡¦ç†ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã“ã¨ã‚‚ã‚ã£ã¦ã‹ï¼Œ
transformsã®å¤§å¹…ãªé«˜é€ŸåŒ–ãŒãªã•ã‚Œã¦ã„ã¾ã™ï¼
å°å…¥ã‚‚ç°¡å˜ãªã®ã§ï¼Œtorchvisio.transformsã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹äººã¯v2ã¸ã®ç§»è¡Œã‚’æ¤œè¨ã—ã¦ã¿ã¦ã‚‚è‰¯ã„ã®ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ï¼
